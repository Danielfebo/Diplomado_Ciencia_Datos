{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f802284-de55-45a1-af22-4d9a3e80bb97",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TAREA NUMERO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1d1e8-e94e-4382-a82d-178d256acde4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concepto de ciencia de datos: Mineria de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2f6c15-8227-4825-bf39-9d7b0f227d59",
   "metadata": {},
   "source": [
    "### Elaborado por:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe3221-18d4-47cc-a677-927e894fbc14",
   "metadata": {},
   "source": [
    "- Daniel Felipe Bohorquez Calderon \n",
    "- C.C. 1006125235\n",
    "- dabohorquez@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067cbb83-8f34-4b59-8e3e-e8e55dcc3f31",
   "metadata": {},
   "source": [
    "Logo de python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774c922-9a11-4763-aadd-455113054441",
   "metadata": {},
   "source": [
    "![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fih1.redbubble.net%2Fimage.462905105.9340%2Fbg%2Cf8f8f8-flat%2C750x%2C075%2Cf-pad%2C750x1000%2Cf8f8f8.u5.jpg&f=1&nofb=1&ipt=b6655058898d9057ec8f2b52d624109a9005bd1a6cc527b3137e05b2e8221e0d&ipo=images \"logo de python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7512b-300e-4d7f-bd62-9a7bb974c71e",
   "metadata": {},
   "source": [
    "### Presentacion del autor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172bc27-0ccf-45f9-bac1-35334536b5b6",
   "metadata": {},
   "source": [
    "Mi nombre es Daniel Felipe Bohorquez Calderon tengo 20 años y soy de Ibagué, actualmente me encuentro cursando el cuarto semestre de la carrera de Estadística en la Universidad Nacional de Colombia, en Bogotá.\n",
    "Soy una persona responsable y enfocado con los temas de interés personal, dentro de esos temas se encuentra la ciberseguridad, deporte, videojuegos, pero principalmente los **mercados financieros**, esa es una de las razones por las cuales estudio Estadística. Dentro de mis hobbies se encontraría jugar basketball, viajar y ver películas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b7f2ac-2ce2-462f-a510-ac597c0d995a",
   "metadata": {},
   "source": [
    "<a href=\"https://ibb.co/rZGCrbM\"><img src=\"https://i.ibb.co/y8nwjh5/IMG-20210401-115829580.jpg\" alt=\"IMG-20210401-115829580\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4782a0f-8c3e-4ad4-8a13-0820c3942a0d",
   "metadata": {},
   "source": [
    "## Algoritmos Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea64d9-e08d-47ea-a60d-3de8adeebd67",
   "metadata": {},
   "source": [
    "En teoría de la probabilidad y minería de datos, un clasificador Naive Bayes es un clasificador probabilístico fundamentado en el teorema de Bayes y algunas hipótesis simplificadoras adicionales.\n",
    "Un clasificador de Naive Bayes asume que la presencia o ausencia de una característica particular no está relacionada con la presencia o ausencia de cualquier otra característica, dada la clase variable. Por ejemplo, una fruta puede ser considerada como una manzana si es roja, redonda y de alrededor de 7 cm de diámetro. Un clasificador de Naive Bayes considera que cada una de estas características contribuye de manera independiente a la probabilidad de que esta fruta sea una manzana, independientemente de la presencia o ausencia de las otras características. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a80835-0e3f-4893-b4b9-48e077283b00",
   "metadata": {},
   "source": [
    "### Concepto probabilistico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd3a506-a43b-429e-86c1-935845eb9c33",
   "metadata": {},
   "source": [
    "En abstracto, el modelo de probabilidad para un clasificador es,\n",
    "$$\n",
    "    p(C|F_1,\\dots,F_n)\n",
    "$$\n",
    "sobre una variable dependiente $C$ , con un pequeño número de resultados (o clases). Esta variable está condicionada por varias variables independientes desde $F_1$ a $F_n$. El problema es que si el número n n de variables independientes es grande (o cuando éstas pueden tomar muchos valores), entonces basar este modelo en tablas de probabilidad se vuelve imposible. Por lo tanto el modelo se reformula para hacerlo más manejable:\n",
    "\n",
    "Usando el teorema de Bayes se escribe: \n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/f2c8595ffd1c98706f679d2586ccb73c95336d71)\n",
    "\n",
    "En la práctica solo importa el numerador, ya que el denominador no depende de $C$  y los valores de $F_i$ son datos, por lo que el denominador es, en la práctica, constante. \n",
    "Este puede ser reescrito aplicando repetidamente la definicion de probabilidad condicional,\n",
    "$ p(C|F_1,\\dots,F_n) $,\n",
    "\n",
    "\\begin{split}\n",
    "    & = p(C)p(F_1,\\dots,F_n|C)\\\\\n",
    "    & = p(C)p(F_1|C)p(F_2,\\dots,F_n|C,F_1)\\\\\n",
    "    & = p(C)p(F_1|C)p(F_2|C,F_1)p(F_3,\\dots,F_n|C,F_1,F_2)\n",
    "\\end{split}\n",
    "\n",
    "y asi sucesivamente.\n",
    "Ahora se asume que cada $F_i$ es independiente de cualquier otra $F_j$ para $j\\neq i$ cuando están condicionadas a $C$ . Esto significa que,\n",
    "\n",
    "$$\n",
    "    p(F_i|C,F_j) = p(F_i|C)\n",
    "$$\n",
    "por lo que la probabilidad compuesta puede expresarse como,\n",
    "\n",
    "$$\n",
    "    p(C)\\displaystyle\\prod_{i=1}^{n} p(F_i|C)\n",
    "$$\n",
    "\n",
    "Esto significa que haciendo estos supuestos, la distribución condicional de $C$ sobre las variables clasificatorias puede expresarse de la siguiente manera: \n",
    "\n",
    "$$\n",
    "    p(C|F_1,\\dots,F_n)=\\frac{1}{Z}p(C)\\displaystyle\\prod_{i=1}^{n} p(F_i|C)\n",
    "$$\n",
    "\n",
    "donde $Z$ es un factor que depende solo de $F_1,\\dots,F_n$, es decir, constante si los valores de $F_i$ son conocidos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db5e25-3209-4390-8f1f-61efe1651711",
   "metadata": {},
   "source": [
    "### Ejemplo de los clasificadores Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f89a20-cccf-4684-adb0-ac47e97e0ee4",
   "metadata": {},
   "source": [
    "#### Extraido de la referencia [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71671fc-84f3-481f-86a0-cc1c076887cd",
   "metadata": {},
   "source": [
    "En este ejemplo, puede usar el conjunto de datos ficticio con tres columnas: clima, temperatura y reproducción. Los dos primeros son características (clima, temperatura) y el otro es la etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbbaed1-d297-4256-86b9-f5264b793c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Weather = ['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "Temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "Play =['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7e524-61b2-46cd-999f-47f21645c6d5",
   "metadata": {},
   "source": [
    "Primero, debe convertir estas etiquetas de cadena en números. por ejemplo: 'Nublado', 'Lluvia', 'Soleado' como 0, 1, 2. Esto se conoce como codificación de etiquetas. Scikit-learn proporciona la biblioteca LabelEncoder para codificar etiquetas con un valor entre 0 y uno menos que el número de clases discretas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "782d2ab8-96fa-4b1c-be97-662ab2de9f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "weather_encoded = le.fit_transform(Weather)\n",
    "print(weather_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceaea60-1eba-4a30-86d2-ec973b5f7d8e",
   "metadata": {},
   "source": [
    "Del mismo modo, también puede codificar columnas temporales y de reproducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb1ad12-8050-406c-923d-02783f6270d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp: [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n",
      "Play : [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Converting string labels into numbers\n",
    "temp_encoded = le.fit_transform(Temp)\n",
    "label = le.fit_transform(Play)\n",
    "\n",
    "print(\"Temp:\", temp_encoded)\n",
    "print(\"Play :\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60d137-7c63-4a04-b9c5-bf5f4fee1a36",
   "metadata": {},
   "source": [
    "Ahora combine ambas características (clima y temperatura) en una sola variable (lista de tuplas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e6dda12-d88f-4217-a39c-6d5f697c597d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (2, 1), (0, 1), (1, 2), (1, 0), (1, 0), (0, 0), (2, 2), (2, 0), (1, 2), (2, 2), (0, 2), (0, 1), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "# Combinig weather and temp into single listof tuples\n",
    "features = [tup for tup in zip(weather_encoded, temp_encoded)]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f70c0c-20a3-45d3-9791-4f43f6aae0d9",
   "metadata": {},
   "source": [
    "Genere un modelo utilizando el clasificador naive bayes en los siguientes pasos:\n",
    "1. Crear un clasificador naive bayes\n",
    "1. Ajustar el conjunto de datos en el clasificador\n",
    "1. Realizar predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018cda85-08a8-4414-8204-3c0679caf34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [1]\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(features,label)\n",
    "\n",
    "#Predict Output\n",
    "predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "print(\"Predicted Value:\", predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa512478-89a1-4395-bdef-36eed154fc16",
   "metadata": {},
   "source": [
    "Aquí, 1 indica que los Jugadores pueden 'Jugar'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29190daf-f136-4060-b654-ef7b1a5aa1fb",
   "metadata": {},
   "source": [
    "### Naive Bayes con múltiples etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3bb97-66ac-4049-b797-a30f924715eb",
   "metadata": {},
   "source": [
    "Lo que se conoce como clasificación Naive Bayes multinomial. Por ejemplo, si desea clasificar un artículo de noticias sobre tecnología, entretenimiento, política o deportes.\n",
    "\n",
    "En la parte de construcción de modelos, puede usar el conjunto de datos de vinos, que es un problema de clasificación de clases múltiples muy famoso. \"Este conjunto de datos es el resultado de un análisis químico de vinos cultivados en la misma región de Italia pero derivados de tres cultivares diferentes\".\n",
    "\n",
    "El conjunto de datos consta de 13 características (alcohol, ácido málico, ceniza, alcalinidad de la ceniza, magnesio, fenoles totales, flavonoides, fenoles no flavonoides, proantocianinas, intensidad del color, matiz, od280/od315_de_vinos_diluidos, prolina) y tipo de cultivo de vino. Estos datos tienen tres tipos de vino Class_0, Class_1 y Class_3. Aquí puedes construir un modelo para clasificar el tipo de vino.\n",
    "\n",
    "Primero, carguemos el conjunto de datos de vino requerido de los conjuntos de datos de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b79e085d-ab7d-4d19-a83f-99fe59e0eb87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e69ca-d7a2-408b-8c2f-61c6cd6dd938",
   "metadata": {},
   "source": [
    "Puede imprimir el objetivo y los nombres de las características para asegurarse de que tiene el conjunto de datos correcto, como tal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b9cdf7-8415-4725-be59-04b2ea14cd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "\n",
      "Labels:  ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# print the names of the 13 features\n",
    "print(\"Features: \", wine.feature_names)\n",
    "\n",
    "# print the label type of wine(class_0, class_1, class_2)\n",
    "print(\"\\nLabels: \", wine.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493008f0-957b-42ae-a3b1-1c00da0cd1bd",
   "metadata": {},
   "source": [
    "Es una buena idea explorar siempre un poco sus datos, para que sepa con qué está trabajando. Aquí, puede ver que se imprimen las primeras cinco filas del conjunto de datos, así como la variable de destino para todo el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "793b1ea2-54d7-4d68-a8ab-4aa059a63832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data(feature)shape\n",
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a77bcbd1-157f-4707-80ea-0e90ebab0053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]]\n"
     ]
    }
   ],
   "source": [
    "# print the wine data features (top 5 records)\n",
    "print(wine.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afabf9b0-8f3d-42a3-97e9-7708fb9facab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# print the wine labels (0:Class_0, 1:class_2, 2:class_2)\n",
    "print(wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904aca1c-2ef6-48dd-9644-157add3a86bb",
   "metadata": {},
   "source": [
    "Primero, separa las columnas en variables dependientes e independientes (o características y etiqueta). Luego divide esas variables en tren y conjunto de prueba<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/Vv7yFBw/Sin-t-tulo.png\" alt=\"Sin-t-tulo\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b612946-bc80-4556-aa47-a7f1f1a83d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, \n",
    "                                                    wine.target, \n",
    "                                                    test_size=0.3,   # 70% training and 30% test\n",
    "                                                    random_state=109) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef36909-9696-4bbd-9ac8-3dfa2b4aebfe",
   "metadata": {},
   "source": [
    "Después de la división, generará un modelo de bosque aleatorio en el conjunto de entrenamiento y realizará una predicción en las características del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fe0e8c4-d3a7-4923-a247-639382920d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f76344-9794-46cb-932b-220bb8a75f64",
   "metadata": {},
   "source": [
    "Después de la generación del modelo, verifique la precisión utilizando valores reales y previstos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91e663f3-22e8-45e2-bd45-5afbd39995da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6501a0-e5c8-41e9-8bda-b28daf28a4f2",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea478e55-7009-48ab-87bb-d4dc491733c9",
   "metadata": {},
   "source": [
    "[1] [Naive Bayes Classification using Scikit-learn](https://www.datacamp.com/tutorial/naive-bayes-scikit-learn)\n",
    "\n",
    "[2] [Clasificador bayesiano ingenuo](https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
